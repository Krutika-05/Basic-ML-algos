{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "My_DT",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFTEQJI3FeFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i0hYTlEFeF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class my_DT:\n",
        "\n",
        "    def __init__(self, criterion=\"gini\", max_depth=8, min_impurity_decrease=0, min_samples_split=2):\n",
        "        # criterion = {\"gini\", \"entropy\"},\n",
        "        # Stop training if depth = max_depth\n",
        "        # Only split node if impurity decrease >= min_impurity_decrease after the split\n",
        "        #   Weighted impurity decrease: N_t / N * (impurity - N_t_R / N_t * right_impurity - N_t_L / N_t * left_impurity)\n",
        "        # Only split node with >= min_samples_split samples\n",
        "        self.criterion = criterion\n",
        "        self.max_depth = int(max_depth)\n",
        "        self.min_impurity_decrease = min_impurity_decrease\n",
        "        self.min_samples_split = int(min_samples_split)\n",
        "\n",
        "\n",
        "    def impurity(self, labels):\n",
        "        # Calculate impurity (unweighted)\n",
        "        # Input is a list (or np.array) of labels\n",
        "        # Output impurity score <= 1\n",
        "        stats = Counter(labels)\n",
        "        N = float(len(labels))\n",
        "        if self.criterion == \"gini\":\n",
        "            pass\n",
        "            # Implement gini impurity\n",
        "\n",
        "\n",
        "        elif self.criterion == \"entropy\":\n",
        "            pass\n",
        "            # Implement entropy impurity\n",
        "\n",
        "\n",
        "        else:\n",
        "            raise Exception(\"Unknown criterion.\")\n",
        "        return 0.73636\n",
        "\n",
        "    def find_best_split(self, pop, X, labels):\n",
        "        # Find the best split\n",
        "        # Inputs:\n",
        "        #   pop:    indices of data in the node\n",
        "        #   X:      independent variables of training data\n",
        "        #   labels: dependent variables of training data\n",
        "        # Output: tuple(best feature to split, weighted impurity score of best split, \n",
        "        #splitting point of the feature, [indices of data in left node, indices of data in right node], \n",
        "        #[weighted impurity score of left node, weighted impurity score of right node])\n",
        "        ######################\n",
        "        best_feature = None\n",
        "        split_impurity = len(pop)\n",
        "        gini_L_node_indices = []\n",
        "        gini_R_node_indices = []\n",
        "        gini_L_node_impurity = 1\n",
        "        gini_R_node_impurity = 1\n",
        "        \n",
        "        check_splitvalue = []\n",
        "        check_splitvalue_impurity = []\n",
        "        \n",
        "        for feature in X.keys():\n",
        "            cans = np.array(X[feature][pop])\n",
        "            for i in range(len(cans)):\n",
        "                left_node = []\n",
        "                right_node = []\n",
        "                left_node_indices = []\n",
        "                right_node_indices = []\n",
        "                for j in range(len(cans)):\n",
        "                    if(cans[j] < cans[i]):\n",
        "                        left_node.append(labels[pop[j]])\n",
        "                        left_node_indices.append(pop[j])\n",
        "                    else:\n",
        "                        right_node.append(labels[pop[j]])\n",
        "                        right_node_indices.append(pop[j])\n",
        "                        \n",
        "                        \n",
        "                left_node_impurity = self.impurity(left_node)\n",
        "                right_node_impurity = self.impurity(right_node)\n",
        "                overall_impurity = ((left_node_impurity * len(left_node)) \n",
        "                                    + right_node_impurity * len(right_node))\n",
        "                check_splitvalue.append(cans[i])\n",
        "                check_splitvalue_impurity.append(overall_impurity)\n",
        "                \n",
        "                if(overall_impurity < split_impurity):\n",
        "                    split_impurity = overall_impurity\n",
        "                    split_value = cans[i]\n",
        "                    split_index = i\n",
        "                    split_feature = feature\n",
        "                    gini_L_node_indices = left_node_indices\n",
        "                    gini_R_node_indices = right_node_indices\n",
        "                    gini_L_node_impurity = (left_node_impurity * len(left_node))\n",
        "                    gini_R_node_impurity = (right_node_impurity * len(right_node))\n",
        "                    \n",
        "                    best_feature = [split_feature, split_impurity, split_value,\n",
        "                                    [gini_L_node_indices,gini_R_node_indices],\n",
        "                                    [gini_L_node_impurity,gini_R_node_impurity]]\n",
        "                    \n",
        "                        \n",
        "        return best_feature\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # X: pd.DataFrame, independent variables, float\n",
        "        # y: list, np.array or pd.Series, dependent variables, int or str\n",
        "        self.classes_ = list(set(list(y)))\n",
        "        labels = np.array(y)\n",
        "        N = len(y)\n",
        "        ##### A Binary Tree structure implemented in the form of dictionary #####\n",
        "        # 0 is the root node\n",
        "        # node i have two childen: left = i*2+1, right = i*2+2\n",
        "        # self.tree[i] = {feature to split on: value of the splitting point} if it is not a leaf\n",
        "        #              = Counter(labels of the training data in this leaf) if it is a leaf node\n",
        "        self.tree = {}\n",
        "        # population keeps the indices of data points in each node\n",
        "        population = {0: np.array(range(N))}\n",
        "        # impurity stores the weighted impurity scores for each node (# data in node * unweighted impurity)\n",
        "        impurity = {0: self.impurity(labels[population[0]]) * N}\n",
        "        #########################################################################\n",
        "        level = 0\n",
        "        nodes = [0]\n",
        "        while level < self.max_depth and nodes:\n",
        "            # Depth-first search to split nodes\n",
        "            next_nodes = []\n",
        "            for node in nodes:\n",
        "                current_pop = population[node]\n",
        "                current_impure = impurity[node]\n",
        "                if len(current_pop) < self.min_samples_split or current_impure == 0:\n",
        "                    # The node is a leaf node\n",
        "                    self.tree[node] = Counter(labels[current_pop])\n",
        "                else:\n",
        "                    # Find the best split using find_best_split function\n",
        "                    best_feature = self.find_best_split(current_pop, X, labels)\n",
        "                    if (current_impure - best_feature[1]) > self.min_impurity_decrease * N:\n",
        "                        # Split the node\n",
        "                        self.tree[node] = (best_feature[0], best_feature[2])\n",
        "                        next_nodes.extend([node * 2 + 1, node * 2 + 2])\n",
        "                        population[node * 2 + 1] = best_feature[3][0]\n",
        "                        population[node * 2 + 2] = best_feature[3][1]\n",
        "                        impurity[node * 2 + 1] = best_feature[4][0]\n",
        "                        impurity[node * 2 + 2] = best_feature[4][1]\n",
        "                    else:\n",
        "                        # The node is a leaf node\n",
        "                        self.tree[node] = Counter(labels[current_pop])\n",
        "            nodes = next_nodes\n",
        "            level += 1\n",
        "        return\n",
        "\n",
        "    def predict(self, X):\n",
        "        # X: pd.DataFrame, independent variables, float\n",
        "        # return predictions: list\n",
        "\n",
        "        predictions = []\n",
        "        for i in range(len(X)):\n",
        "            node = 0\n",
        "            while True:\n",
        "                if type(self.tree[node]) == Counter:\n",
        "                    label = list(self.tree[node].keys())[np.argmax(self.tree[node].values())]\n",
        "                    predictions.append(label)\n",
        "                    break\n",
        "                else:\n",
        "                    if X[self.tree[node][0]][i] < self.tree[node][1]:\n",
        "                        node = node * 2 + 1\n",
        "                    else:\n",
        "                        node = node * 2 + 2\n",
        "        return predictions\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        # X: pd.DataFrame, independent variables, float\n",
        "        # Eample:\n",
        "        # self.classes_ = {\"2\", \"1\"}\n",
        "        # the reached node for the test data point has {\"1\":2, \"2\":1}\n",
        "        # then the prob for that data point is {\"2\": 1/3, \"1\": 2/3}\n",
        "        # return probs = pd.DataFrame(list of prob, columns = self.classes_)\n",
        "\n",
        "        predictions = []\n",
        "        for i in range(len(X)):\n",
        "            node = 0\n",
        "            while True:\n",
        "                if type(self.tree[node]) == Counter:\n",
        "                    N = float(np.sum(list(self.tree[node].values())))\n",
        "                    predictions.append({key: self.tree[node][key] / N for key in self.classes_})\n",
        "                    break\n",
        "                else:\n",
        "                    if X[self.tree[node][0]][i] < self.tree[node][1]:\n",
        "                        node = node * 2 + 1\n",
        "                    else:\n",
        "                        node = node * 2 + 2\n",
        "        probs = pd.DataFrame(predictions, columns=self.classes_)\n",
        "        return probs\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGjNeEs1FeF9",
        "colab_type": "code",
        "colab": {},
        "outputId": "cae1a821-104c-4ee5-f3bd-e36751032cf6"
      },
      "source": [
        "data_train = pd.read_csv(\"../data/Iris_train.csv\")\n",
        "# Separate independent variables and dependent variables\n",
        "independent = [\"SepalLengthCm\",\t\"SepalWidthCm\",\t\"PetalLengthCm\",\t\"PetalWidthCm\"]\n",
        "X = data_train[independent]\n",
        "y = data_train[\"Species\"]\n",
        "# Train model\n",
        "clf = my_DT()\n",
        "clf.fit(X,y)\n",
        "# Load testing data\n",
        "data_test = pd.read_csv(\"../data/Iris_test.csv\")\n",
        "X_test = data_test[independent]\n",
        "# Predict\n",
        "predictions = clf.predict(X_test)\n",
        "# Predict probabilities\n",
        "probs = clf.predict_proba(X_test)\n",
        "# Print results\n",
        "for i,pred in enumerate(predictions):\n",
        "    print(\"%s\\t%f\" %(pred, probs[pred][i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iris-setosa\t1.000000\n",
            "Iris-setosa\t0.291339\n",
            "Iris-setosa\t0.291339\n",
            "Iris-setosa\t0.291339\n",
            "Iris-setosa\t0.291339\n",
            "Iris-setosa\t0.291339\n",
            "Iris-setosa\t0.291339\n",
            "Iris-setosa\t0.291339\n",
            "Iris-setosa\t0.291339\n",
            "Iris-setosa\t0.291339\n",
            "Iris-setosa\t0.291339\n",
            "Iris-setosa\t0.291339\n",
            "Iris-setosa\t0.291339\n",
            "Iris-setosa\t0.291339\n",
            "Iris-setosa\t0.291339\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UubWP2aLFeGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}